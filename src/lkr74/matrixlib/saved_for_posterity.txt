		// a test to show that cache-optimising and loop-unrolling matrix multiplication can be totally counterproductive
		// (supposed to be testrun in a main() method)
		Matrix R = new Matrix("R", 19, 12, Matrix.Type.Random);
		Matrix Rt = R.transpose(COPY), Rres;
		Matrix.DEBUG_LEVEL--;
		
		tStart = System.nanoTime();
		for (int i = 0; i < iters; i++) { Rres = R.multiply(Rt); Rres.det++; }
		tEnd = System.nanoTime();
		System.out.printf("Matrix.multiply() averaged %.1f ns\n", (double)(tEnd - tStart)/(double)iters);

		tStart = System.nanoTime();
		for (int i = 0; i < iters; i++) { Rres = R.multiply_cacheopt(Rt); Rres.det++; }
		tEnd = System.nanoTime();
		System.out.printf("Matrix.multiply_cacheopt() averaged %.1f ns\n", (double)(tEnd - tStart)/(double)iters);
		Matrix.DEBUG_LEVEL++;


	// method find the closest node to the suppplied one by constructing coordinate-wise sortings and doing an expansive nearest-neighbour search
	// always choosing the shortest coordinate-neighbour index to step out along, until three indexes from the reindexing arrays match up
	// note: method was a naive approach that does not work!
	public int closestNode(int n, boolean sort) {
		
		double[] sortX, sortY, sortZ; 
		int[] idxX, idxY, idxZ, sortIX, sortIY, sortIZ;
		if (nodeCoordSort == null || sort) {			// initialise coordinate sortings if it wasn't done, or if requested
			nodeCoordSort = new double[3][];
			nodeCoordSortI = new int[6][];
			
			sortX = nodeCoordSort[0] = new double[nodes]; idxX = nodeCoordSortI[0] = new int[nodes];
			sortY = nodeCoordSort[1] = new double[nodes]; idxY = nodeCoordSortI[1] = new int[nodes];
			sortZ = nodeCoordSort[2] = new double[nodes]; idxZ = nodeCoordSortI[2] = new int[nodes];
			
			int n1 = 0;
			for (int n3 = 0; n1 < nodes; n1++) {
				sortX[n1] = node[n3++]; idxX[n1] = n1;						// collect x-coordinates
				sortY[n1] = node[n3++]; idxY[n1] = n1;						// collect y-coordinates
				sortZ[n1] = node[n3++]; idxZ[n1] = n1;						// collect z-coordinates
			}
			if (nodeWork != null)
				for (int n3 = 0, nEnd = n1 + nodes - node.length / 3; n1 < nEnd; n1++) {
					sortX[n1] = nodeWork[n3++]; idxX[n1] = n1;
					sortY[n1] = nodeWork[n3++]; idxX[n1] = n1;
					sortZ[n1] = nodeWork[n3++]; idxX[n1] = n1;
				}
			sortIndexedDoubles(sortX, sortIX = nodeCoordSortI[3] = idxX.clone(), idxX);
			sortIndexedDoubles(sortY, sortIY = nodeCoordSortI[4] = idxY.clone(), idxY);
			sortIndexedDoubles(sortZ, sortIZ = nodeCoordSortI[5] = idxZ.clone(), idxZ);
		} else {
			sortX = nodeCoordSort[0]; sortY = nodeCoordSort[1]; sortZ = nodeCoordSort[2];
			idxX = nodeCoordSortI[0]; idxY = nodeCoordSortI[1]; idxZ = nodeCoordSortI[2];
			sortIX = nodeCoordSortI[3]; sortIY = nodeCoordSortI[4]; sortIZ = nodeCoordSortI[5];
		}
		
		int nX = idxX[n], nY = idxY[n], nZ = idxZ[n];
		int ngbXl = nX - 1, ngbXu = nX + 1, ngbYl = nY - 1, ngbYu = nY + 1, ngbZl = nZ - 1, ngbZu = nZ + 1, nC = -1, ngbChoice;
		double dltXl, dltXu, dltXmin, dltYl, dltYu, dltYmin, dltZl, dltZu, dltZmin;
		double vXl = ngbXl < 0 ? -1e100 : sortX[ngbXl], vXu = ngbXu >= nodes ? 1e100 : sortX[ngbXu];
		double vYl = ngbYl < 0 ? -1e100 : sortY[ngbYl], vYu = ngbYu >= nodes ? 1e100 : sortY[ngbYu];
		double vZl = ngbZl < 0 ? -1e100 : sortZ[ngbZl], vZu = ngbZu >= nodes ? 1e100 : sortZ[ngbZu];
		int idxXl = ngbXl < 0 ? -1 : sortIX[ngbXl], idxXu = ngbXu >= nodes ? -2 : sortIX[ngbXu];
		int idxYl = ngbYl < 0 ? -3 : sortIY[ngbYl], idxYu = ngbYu >= nodes ? -4 : sortIY[ngbYu];
		int idxZl = ngbZl < 0 ? -5 : sortIZ[ngbZl], idxZu = ngbZu >= nodes ? -6 : sortIZ[ngbZu];
		
		while(true) {
			if		((idxXl == idxYl || idxXl == idxYu) && (idxXl == idxZl || idxXl == idxZu)) {
				nC = idxXl; break; }
			else if	((idxXu == idxYl || idxXu == idxYu) && (idxXu == idxZl || idxXu == idxZu)) {
				nC = idxXu; break; }
			
			dltXl = sortX[nX] - vXl; dltYl = sortY[nY] - vYl; dltZl = sortZ[nZ] - vZl;
			dltXu = vXu - sortX[nX]; dltYu = vYu - sortY[nY]; dltZu = vZu - sortZ[nZ];
			ngbChoice = 0;
			if (dltXl < dltXu) { dltXmin = dltXl; ngbChoice |= 1;  } else { dltXmin = dltXu; ngbChoice |= 2; } 
			if (dltYl < dltYu) { dltYmin = dltYl; ngbChoice |= 4;  } else { dltYmin = dltYu; ngbChoice |= 8; } 
			if (dltZl < dltZu) { dltZmin = dltZl; ngbChoice |= 16; } else { dltZmin = dltZu; ngbChoice |= 32; } 
			
			if (dltXmin < dltYmin) {	if (dltZmin < dltXmin) ngbChoice &= 16+32; else ngbChoice &= 1+2;
			} else {					if (dltZmin < dltYmin) ngbChoice &= 16+32; else ngbChoice &= 4+8;}
			
			switch (ngbChoice) {			// expand search along the coordinate neighbourhood which is closest to node
				case 1:  if (--ngbXl < 0)		{	vXl = -1e100; idxXl = -1; } else { vXl = sortX[ngbXl]; idxXl = idxX[ngbXl]; } break;	
				case 2:  if (++ngbXu >= nodes) {	vXu = 1e100; idxXu = -2; } 	else { vXu = sortX[ngbXu]; idxXu = idxX[ngbXu]; } break;	
				case 4:  if (--ngbYl < 0)		{	vYl = -1e100; idxYl = -3; } else { vYl = sortY[ngbYl]; idxYl = idxY[ngbYl]; } break;	
				case 8:  if (++ngbYu >= nodes) {	vYu = 1e100; idxYu = -4; } 	else { vYu = sortY[ngbYu]; idxYu = idxY[ngbYu]; } break;	
				case 16: if (--ngbZl < 0)		{	vZl = -1e100; idxZl = -5; } else { vZl = sortZ[ngbZl]; idxZl = idxZ[ngbZl]; } break;	
				case 32: if (++ngbZu >= nodes) {	vZu = 1e100; idxZu = -6; } 	else { vZu = sortZ[ngbZu]; idxZu = idxZ[ngbZu]; } break;	
			}
		}	
		return nC;
	}





	// splits current octree node into 8 partitions (uses method of filling cache-sized blocks (32 bytes) at a time
	// note: microbenchmark show this method as actually slower, perhaps because of more complex looping involved
	public double split2(FEM1 fem, int maxNodes) {
		double xC = (xP + xM) * .5, yC = (yP + yM) * .5, zC = (zP + zM) * .5;		// find splitting centroid of this octree node
		double[] nodeCoord = fem.node;
		// worst case allocation of octosplitted node arrays
		int nMMM = 0, nPMM = 8, nMPM = 16, nPPM = 24, nMMP = 32, nPMP = 40, nMPP = 48, nPPP = 56;
		int nMMM8=0, nPMM8=0, nMPM8=0, nPPM8=0, nMMP8=0, nPMP8=0, nMPP8=0, nPPP8=0;
		int nodesRm8 = nodes & 7, octants = 0;
		// align temporary node arrays to 8-slot divisions
		int[] nodeOct = new int[(nodesRm8 == 0 ? nodes & 0xFFFFFFF8 : (nodes & 0xFFFFFFF8) + 8) * 8];
		
		for (int n = 0; n < nodes; n++) {											// distribute node references into the 8 octants
			int n3 = node[n] * 3;
			double xN = nodeCoord[n3++], yN = nodeCoord[n3++], zN = nodeCoord[n3];
			if (xN <= xC) {
				if (yN <= yC) {	if (zN <= zC)	{ nodeOct[nMMM++] = node[n]; if (++nMMM8 > 7) {nMMM+=56; nMMM8=0;}}
								else			{ nodeOct[nMMP++] = node[n]; if (++nMMP8 > 7) {nMMP+=56; nMMP8=0;}}}
				else {			if (zN <= zC)	{ nodeOct[nMPM++] = node[n]; if (++nMPM8 > 7) {nMPM+=56; nMPM8=0;}}
								else			{ nodeOct[nMPP++] = node[n]; if (++nMPP8 > 7) {nMPP+=56; nMPP8=0;}}}
			} else {
				if (yN <= yC) {	if (zN <= zC)	{ nodeOct[nPMM++] = node[n]; if (++nPMM8 > 7) {nPMM+=56; nPMM8=0;}}
								else			{ nodeOct[nPMP++] = node[n]; if (++nPMP8 > 7) {nPMP+=56; nPMP8=0;}}}
				else {			if (zN <= zC)	{ nodeOct[nPPM++] = node[n]; if (++nPPM8 > 7) {nPPM+=56; nPPM8=0;}}
								else			{ nodeOct[nPPP++] = node[n]; if (++nPPP8 > 7) {nPPP+=56; nPPP8=0;}}}
			}
		}
		octant = new FEM1Octree[8];
		FEM1Octree child = null;
		int[] nodeChild = null;
		
		nMMM = (nMMM >> 6 << 3) + nMMM8; nPMM = (nPMM >> 6 << 3) + nPMM8; nMPM = (nMPM >> 6 << 3) + nMPM8; nPPM = (nPPM >> 6 << 3) + nPPM8;
		nMMP = (nMMP >> 6 << 3) + nMMP8; nPMP = (nPMP >> 6 << 3) + nPMP8; nMPP = (nMPP >> 6 << 3) + nMPP8; nPPP = (nPPP >> 6 << 3) + nPPP8;
		
		if (nMMM > 0) {
			nodeChild = new int[nMMM];
			int n = 0, n8 = 0, nEnd64 = nMMM>>3;
			for (int n64 = 0; n64<nEnd64; n64++) {
				n8 = n64 << 6; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
				nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
			}
			n8 = nEnd64 << 6; while (nMMM8-- > 0) nodeChild[n++] = nodeOct[n8++];
			octant[OCT_MMM] = child = new FEM1Octree(this, OCT_MMM, nMMM, nodeChild);		// initialise octant MMM
			child.xM = xM; child.yM = yM; child.zM = zM; child.xP = xC; child.yP = yC; child.zP = zC;
			if (nMMM > maxNodes) { octantIterator = (octantIterator << 3) | OCT_MMM; octants++; }
		}
		if (nPMM > 0) {
			nodeChild = new int[nPMM];
			int n = 0, n8 = 0, nEnd64 = nPMM>>3;
			for (int n64 = 0; n64<nEnd64; n64++) {
				n8 = (n64 << 6) + 8; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
				nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
			}
			n8 = (nEnd64 << 6) + 8; while (nPMM8-- > 0) nodeChild[n++] = nodeOct[n8++];
			octant[OCT_PMM] = child = new FEM1Octree(this, OCT_PMM, nPMM, nodeChild);		// initialise octant PMM
			child.xM = xC; child.yM = yM; child.zM = zM; child.xP = xP; child.yP = yC; child.zP = zC;
			if (nPMM > maxNodes) { octantIterator = (octantIterator << 3) | OCT_PMM; octants++; }
		}
		if (nMPM > 0) {
			nodeChild = new int[nMPM];
			int n = 0, n8 = 0, nEnd64 = nMPM>>3;
			for (int n64 = 0; n64<nEnd64; n64++) {
				n8 = (n64 << 6) + 16; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
				nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
			}
			n8 = (nEnd64 << 6) + 16; while (nMPM8-- > 0) nodeChild[n++] = nodeOct[n8++];
			octant[OCT_MPM] = child = new FEM1Octree(this, OCT_MPM, nMPM, nodeChild);		// initialise octant MPM
			child.xM = xM; child.yM = yC; child.zM = zM; child.xP = xC; child.yP = yP; child.zP = zC;
			if (nMPM > maxNodes) { octantIterator = (octantIterator << 3) | OCT_MPM; octants++; }
		}
		if (nPPM > 0) {
			nodeChild = new int[nPPM];
			int n = 0, n8 = 0, nEnd64 = nPPM>>3;
			for (int n64 = 0; n64<nEnd64; n64++) {
				n8 = (n64 << 6) + 24; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
				nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
			}
			n8 = (nEnd64 << 6) + 24; while (nPPM8-- > 0) nodeChild[n++] = nodeOct[n8++];
			octant[OCT_PPM] = child = new FEM1Octree(this, OCT_PPM, nPPM, nodeChild);		// initialise octant MMM
			child.xM = xC; child.yM = yC; child.zM = zM; child.xP = xP; child.yP = yP; child.zP = zC;
			if (nPPM > maxNodes) { octantIterator = (octantIterator << 3) | OCT_PPM; octants++; }
		}
		if (nMMP > 0) {
			nodeChild = new int[nMMP];
			int n = 0, n8 = 0, nEnd64 = nMMP>>3;
			for (int n64 = 0; n64<nEnd64; n64++) {
				n8 = (n64 << 6) + 32; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
				nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
			}
			n8 = (nEnd64 << 6) + 32; while (nMMP8-- > 0) nodeChild[n++] = nodeOct[n8++];
			octant[OCT_MMP] = child = new FEM1Octree(this, OCT_MMP, nMMP, nodeChild);		// initialise octant MMP
			child.xM = xM; child.yM = yM; child.zM = zC; child.xP = xC; child.yP = yC; child.zP = zP;
			if (nMMP > maxNodes) { octantIterator = (octantIterator << 3) | OCT_MMP; octants++; }
		}
		if (nPMP > 0) {
			nodeChild = new int[nPMP];
			int n = 0, n8 = 0, nEnd64 = nPMP>>3;
			for (int n64 = 0; n64<nEnd64; n64++) {
				n8 = (n64 << 6) + 40; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
				nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
			}
			n8 = (nEnd64 << 6) + 40; while (nPMP8-- > 0) nodeChild[n++] = nodeOct[n8++];
			octant[OCT_PMP] = child = new FEM1Octree(this, OCT_PMP, nPMP, nodeChild);		// initialise octant PMP
			child.xM = xC; child.yM = yM; child.zM = zC; child.xP = xP; child.yP = yC; child.zP = zP;
			if (nPMP > maxNodes) { octantIterator = (octantIterator << 3) | OCT_PMP; octants++; }
		}
		if (nMPP > 0) {
			nodeChild = new int[nMPP];
			int n = 0, n8 = 0, nEnd64 = nMPP>>3;
			for (int n64 = 0; n64<nEnd64; n64++) {
				n8 = (n64 << 6) + 48; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
				nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
			}
			n8 = (nEnd64 << 6) + 48; while (nMPP8-- > 0) nodeChild[n++] = nodeOct[n8++];
			octant[OCT_MPP] = child = new FEM1Octree(this, OCT_MPP, nMPP, nodeChild);		// initialise octant MPP
			child.xM = xM; child.yM = yC; child.zM = zC; child.xP = xC; child.yP = yP; child.zP = zP;
			if (nMPP > maxNodes) { octantIterator = (octantIterator << 3) | OCT_MPP; octants++; }
		}
		if (nPPP > 0) {
			nodeChild = new int[nPPP];
			int n = 0, n8 = 0, nEnd64 = nPPP>>3;
			for (int n64 = 0; n64<nEnd64; n64++) {
				n8 = (n64 << 6) + 56; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
				nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++]; nodeChild[n++] = nodeOct[n8++];
			}
			n8 = (nEnd64 << 6) + 56; while (nPPP8-- > 0) nodeChild[n++] = nodeOct[n8++];
			octant[OCT_PPP] = child = new FEM1Octree(this, OCT_PPP, nPPP, nodeChild);		// initialise octant PPP
			child.xM = xC; child.yM = yC; child.zM = zC; child.xP = xP; child.yP = yP; child.zP = zP;
			if (nPPP > maxNodes) { octantIterator = (octantIterator << 3) | OCT_PPP; octants++; }
		}
		octantIterator |= (octants << 24);
		node = null;					// a branch doesnt need node references
		return octantNodeDisbalance(nodes, nMMM, nPMM, nMPM, nPPM, nMMP, nPMP, nMPP, nPPP);
	}




		// block from findBTF() with proper array scanning of transferred BTF indexes
		// has been replaced by a boolean array checking whether an element has been "used up"

		int[] Hc = idxBTF[1], Hr = idxBTF[0];
		int iHr = 0, iHc = 0;
		while (iU != iEndU) {
			int c = Hc[iHc++] = Uc[iU++];
			int[] edge = vertex[c + partC].edge;
			for (int e = 0, eEnd = vertex[c + partC].edges; e < eEnd; e++) {
				int r = edge[e] & (0xFFFFFFFF - BipartiteVertex.FLAGS);
				boolean inHr = false;
				for (int i = 0; i < iHr; i++)									// test if r of adj(c) is already in Hr
					if (Hr[i] == r) { inHr = true; break; }
				if (!inHr) {
					Hr[iHr++] = r;												// insert r into Hr[] if it didn't exist
					flagR[r] = true;
					int cMate = pairing[r];
					if (cMate == -1) { continue; }
					boolean inU = false, inHc = false;
					for (int i = iU; i < iEndU; i++)							// if pairing of r is not in U...
						if (Uc[i] == cMate) { inU = true; break; }
					if (!inU) {
						for (int i = 0; i < iHc; i++)							// and pairing of r is not in Hc
							if (Hc[i] == cMate) { inHc = true; break; }	
						if (!inHc) {
							Uc[iEndU++] = cMate;								// then add it to U
							flagC[cMate] = true;
						}
					}
				}
			}
		}



	public static Matrix multiply3(Matrix A, Matrix B, Matrix C, boolean copy) {

		int aM = A.M, aN = A.N, bM = B.M, bN = B.N, cM = C.M, cN = C.N;
		if (aM<1||aN<1||bM<1||bN<1||cM<1||cN<1) 	throw new InvalidParameterException("Matrix.multiply3(): Invalid matrix dimensions.");
		if (aN != bM) 								throw new InvalidParameterException("Matrix.multiply3(): Nonmatching matrix dimensions.");
		if (cM != aM && cN != bN) 					throw new InvalidParameterException("Matrix.multiply3(): Nonmatching matrix dimensions.");
		
		double[] dataA = A.getDataRef()[0], dataB = B.getDataRef()[0], dataC = C.getDataRef()[0];
		
		double[] dataD = dataC;
		Matrix D = C;
		if (copy) {
			D = new Matrix((Matrix.DEBUG_LEVEL > 1 ? "(" + A.name + "." + B.name + ")" : "P"), aM, bN);
			dataD = D.data = new double[aM * bN];
		}

		for (int k = 0, kM = k * aM; k < aN; k++) {
			for (int i = 0, iNk = k; i < aM; i++, iNk += aN) {
				int iM = i * aM;
				double v = dataA[iNk];
				if (!nearZero(v))
						for (int kMj = kM, iMj = iM, kMjEnd = kMj + bM; kMj < kMjEnd; kMj++, iMj++)
							dataD[iMj] = v * dataB[kMj] + dataC[iMj];
				else	for (int iMj = iM, iMjEnd = iMj + bM; iMj < iMjEnd; iMj++)
							dataD[iMj] += dataC[iMj];
//				mulFlops_DEBUG += bN;
//				mulAdops_DEBUG += bN;
			}
		}
		
		if (DEBUG_LEVEL > 1) System.out.println(D.toString());
		D.clearNull();
		D.halfBandwidth = -1;
		D.bitImage = new BinBitImage(D);				// bitImage needs full reconstitution
		return D;
	}





	// edge cut method takes an optional edge index if it has been found beforehand
	public boolean cutEdge(int v1, int v2, int e) {
		
		FrontalDAGVertex vtx = vertex[v1];
		if (vtx.cutedges > vtx.edges) vtx.purgeFlagged();			// clear exsessive erased edges
		int e1 = 0, e1End = vtx.edges + vtx.cutedges;
		boolean edgeFound = false;
		
		if (e == -1) {
			for (; e1 < e1End; e1++)
				if (vtx.edge(e1) == v2) { edgeFound = true; break; }		// if sought edge was found	
			if (!edgeFound) return false;
		} else e1 = e;

		// TODO: this block seems irrelevant since cutedges are purged anyway when exceeding live edges
		// and the optimal balance between the two must be about 50/50 anyway
		if (e1End + vtx.cutedges >= vtx.edge.length) {		// overwrite some erased edge if array is full
			for (int e2 = e1End - 1; e2 >= 0; e2--)
				if (vtx.edge[e2] != -1)						// seek backwards for first non-flagged edge
					vtx.edge[e1] = vtx.edge[e2];			// store it over the deleted edge
		} else {
		// end of block
			// save the cut-flagged edge index at back of the array
			if (--vtx.edges == 0) vtx.cutedges = 0;			// if last edge was cut, cut-flag count becomes irrelevant
			else {
				vtx.edge[vtx.edge.length - ++vtx.cutedges] = e1;
				vtx.edge[e1] = -1;							// -1 cutflags an edge, making impossible to match it with another vertex
			}
			edges--;
		}		
		return true;
	}




		// test routine to check if cache misses happen because of usage of two separate arrays
		// within same iteration, and whether splitting the iterators apart is a better strategy
		// result:
		// combined iterator averaged 86967,1 ns
		// separated iterator averaged 95925,1 ns
		// no cache gains from iterating arrays individually, combined iteration gives a shorter instruction run

		double[] db = new double[100000];
		int[] in = new int[100000];
		tStart = System.nanoTime();
		for (int i = 0; i < 10000; i++) {
			for (int e = 0, eI = 1; e < (100000-6); e += eI) {
				if (++eI > 6) eI = 1;
				db[e] = (double)i * (double)e;
				in[e] = i * e;
			}
		}
		tEnd = System.nanoTime();
		System.out.printf("combined iterator averaged %.1f ns\n", (double)(tEnd - tStart)/10000);
		System.out.println(db[7]);
		tStart = System.nanoTime();
		for (int i = 0; i < 10000; i++) {
			for (int e = 0, eI = 1; e < (100000-6); e += eI) {
				if (++eI > 6) eI = 1;
				db[e] = (double)i * (double)e;
			}
			for (int e = 0, eI = 1; e < (100000-6); e += eI) {
				if (++eI > 6) eI = 1;
				in[e] = i * e;
			}
		}
		tEnd = System.nanoTime();
		System.out.printf("separated iterator averaged %.1f ns\n", (double)(tEnd - tStart)/10000);
		System.out.println(db[7]);
		if(1==1) return;	




// test routine microbenchmark for double operations versus float showed that float is only marginally (1-2%) faster than double

		double xx = 3456, yy = 7890, zz = 1;
		tStart = System.nanoTime();
		for (int i = 0; i < iters; i++) {
			xx -= zz; yy += zz;
			if (zz > 10e6) zz /= xx;
			if (zz < 10e-6) zz *= yy; 
			if (xx > 10e6) xx /= 2;
			if (yy > 10e6) yy /= 2;
		}
		tEnd = System.nanoTime();
		System.out.println(xx + " " + yy + " " + zz);
		System.out.printf("double ops averaged %.1f ns, took %.1f ns\n", (double)(tEnd - tStart)/iters, (double)(tEnd - tStart));
		float xxf = 3456, yyf = 7890, zzf = 1;
		tStart = System.nanoTime();
		for (int i = 0; i < iters; i++) {
			xxf -= zzf; yyf += zzf;
			if (zzf > 10e6) zzf /= xxf;
			if (zzf < 10e-6) zzf *= yyf; 
			if (xxf > 10e6) xxf /= 2;
			if (yyf > 10e6) yyf /= 2;
		}
		tEnd = System.nanoTime();
		System.out.println(xxf + " " + yyf + " " + zzf);
		System.out.printf("float ops averaged %.1f ns, took %.1f ns\n", (double)(tEnd - tStart)/iters, (double)(tEnd - tStart));




	// extend-adds two supplied frontal matrices fm1 & fm2 into a parent frontal matrix fm3
	static FrontalMatrix extendAdd(int pivot, FrontalMatrix  fm1, FrontalMatrix fm2) {
		
		FrontalMatrix fm3 = new FrontalMatrix();
		fm3.pivot = pivot;
		
		// find out how many rows & columns we need to extend into the current frontal matrix
		// duplicate rows/columns must be added, non-duplicate must receive extra space	
		// idxM holds the interspersed indexation of the extend-added rows, thus allocated for worst-case
		int[] idxM1 = fm1.idxCR, idxM2 = fm2.idxCR;
		int i1 = 1, i2 = 1, sumM = 0, fm1M = fm1.r, fm2M = fm2.r;
		// this.idxM holds the interspersed indexation of the extend-added rows, thus allocated for worst-case
		int[] idxM = fm3.idxCR = new int[fm1M + fm2M + fm1.c + fm2.c];
		int[] aRefM = new int[fm1M + fm2M];		// indexes array combinations for fast iterative access
		
		// create array idxM listing the resultant constituent row indexes
		// and aRefM, storing type of operation to apply on resultant row
		for (; i1 < fm1M && i2 < fm2M; sumM++) {
			int idx1 = idxM1[i1], idx2 = idxM2[i2];
			if (idx1 > idx2) { idxM[sumM] = idx2; i2++; aRefM[sumM] = 2; }
			else if (idx1 < idx2) { idxM[sumM] = idx1; i1++; aRefM[sumM] = 1; }
			else { idxM[sumM] = idx1; i1++; i2++; aRefM[sumM] = 3; }
		}
		// if one array was depleted before the other, deplete the other array too
		while (i1 < fm1M) idxM[sumM++] = idxM1[i1++];
		while (i2 < fm2M) idxM[sumM++] = idxM2[i2++];
		fm3.r = sumM;

		// this.idxN holds the interspersed indexation of the extend-added columns, thus allocated for worst-case
		int[] idxN1 = fm1.idxCR, idxN2 = fm2.idxCR;
		i1 = 1; i2 = 1;
		int fm1N = fm1.c, fm2N = fm2.c, sumN = 0;
		int[] idxN = fm3.idxCR = new int[fm1M + fm2M + fm1N + fm2N];
		int[] aRefN = new int[fm1N + fm2N];		// indexes array combinations for fast iterative access
		
		// create array idxN listing the resultant constituent column indexes
		// and aRefM, storing type of operation to apply on resultant column
		for (; i1 < fm1N && i2 < fm2N; sumN++) {
			int idx1 = idxN1[fm1.cTot + i1], idx2 = idxN2[fm2.cTot + i2];
			if (idx1 > idx2) { idxN[fm3.cTot + sumN] = idx2; aRefN[sumN] = 2; }
			else if (idx1 < idx2) { idxN[fm3.cTot + sumN] = idx1; aRefN[sumN] = 1; }
			else { idxN[fm3.cTot + sumN] = idx1; i1++; i2++; aRefN[sumN] = 3; }
		}
		// if one array was depleted before the other, deplete the other array too
		while (i1 < fm1N) idxN[fm3.cTot + sumN++] = idxN1[i1++];
		while (i2 < fm2N) idxN[fm3.cTot + sumN++] = idxN2[i2++];
		fm3.c = sumN;
		
		// allocate frontal matrix fm3, expand it out to square form for applying LU decomposition
		int size_fm3 = sumM > sumN ? sumM : sumN;
		double[] data3 = fm3.data = new double[size_fm3 * size_fm3];	
		double[] data1 = fm1.data, data2 = fm2.data;
		
		// add-extend the contribution parts of fm1 & fm2 int fm3, aRefM & aRefN decide whether to add or copy
		for (int i = 0, j1 = 1, j2 = 1; i < sumM; i++, j1++, j2++) {
			int iN = i * size_fm3;
			for (int j = 0; j < sumN; j++) {
				switch (aRefM[i]) {
				case 1: data3[iN + j] = data1[j1++]; break;						// extend with entire row from fm1
				case 2: data3[iN + j] = data2[j2++]; break;						// extend with entire row from fm2
				case 3:
					switch (aRefN[j]) {											// combine row from fm1 & fm2
					case 1: data3[iN + j] = data1[j1++]; break;					// extend with element from fm1
					case 2: data3[iN + j] = data2[j2++]; break;					// extend with element from fm2
					case 3: data3[iN + j] = data1[j1++] + data2[j2++]; break;	// combine elements from fm1 & fm2
					}
				}
			}
		}
		
		fm3.decomposeLU();									// apply LU decomposition, frontal matrix is finalised
		return fm3;
	}




(This snippet is from FrontalMatrix.add() method)

						// we need to continue adding to column within the extras field, but it has a separately sorted indexation
						// so, we have to restart comparisons at this point, and extend iteration bounds
						if (fmC.nExtraR > 0) {
							idxC = idxCRC[iCEnd]; idxP = idxCR[iPEnd];
							int iCEndE = iCEnd + fmC.nExtraR, iPEndE = iPEnd + nExtraR;
							while (iC < iCEndE && iP < iPEndE) {
								if (idxC < idxP) { idxC = idxCRC[++iC];	idC += cTotC; }		// child's column index lower than parents
								else if (idxC > idxP) { idxP = idxCR[++iP];	idP += cTot; }	// child's column index higher than parents
								else {	
									data[idP] = dataC[idC];
									data[idC] = 0;									// every contribution must only happen once, so zero it out
									idC += cTotC; idP += cTot;						// step down both the matching columns
									idxC = idxCRC[++iC]; idxP = idxCR[++iP];		// advance in both index arrays
								}
							}
						}







				// join in expected extras from root into children's extras indexes
				extraJoinDataC[1][2] = fmP.nExtraC;							// how many extras column indexes from root
				extraJoinDataC[1][3] = cPe + fmP.nContribC;					// the offset to extras indexes in root
				extraJoinDataC[1][4] = 2;									// we want to get offsets for parent's indexes
				joinIndexes(contribJoinDataC, fmP.idxCR);
				extraJoinDataR[1][2] = fmP.nExtraC;							// how many extras column indexes from root
				extraJoinDataR[1][3] = cPe + fmP.nContribC;					// the offset to extras indexes in root
				extraJoinDataR[1][4] = 2;									// we want to get offsets for parent's indexes
				joinIndexes(contribJoinDataC, fmP.idxCR);



	public FrontalMatrix(NSPMatrix A, int pivot, int nExtraP, int[] contribR, int[] contribC, int nExtraR, int nExtraC) {

		NspNode[] bHsp = A.Hsp[pivot].array, bVsp = A.Vsp[pivot].array;
		// if there are no values in the row or column, return empty frontal matrix, let caller handle problemn
		if (bHsp == null || bVsp == null) return;

		this.pivot = pivot;

		int offH = A.pivotNsp[pivot].offH, offV = A.pivotNsp[pivot].offV;
		nContribR = A.Vsp[pivot].nodes - offV - 1;
		nContribC = A.Hsp[pivot].nodes - offH - 1;
		int nContribR2 = contribR[0] + 1, nContribC2 = contribC[0] + 1;
		r = nExtraP + nContribR2 + nExtraR; rTot = r + r/4;
		c = nExtraP + nContribC2 + nExtraC; cTot = c + c/4;
		data = new double[rTot * cTot];
		idxCR = new int[rTot + cTot];

		// initialise frontal row & column from pivot's sparse row & column
		int jP = nExtraP * cTot + nExtraP;					// offset beyond extra pivot rows & columns
		int j = offH, j2 = 1, p = bHsp[offH].c, jFM = jP;
		while (contribC[j2] < p) j2++;						// skip past contrib.column indexes lower than current pivot

		while (j <= nContribC && j2 < nContribC2) {
			int c1 = bHsp[j].c;
			if (c1 > contribC[j2]) {
				idxCR[jFM++] = contribC[j2++];				// fill-in from child matrices happened
				continue;
			} else if (c1 < contribC[j2])
				data[jFM] = bHsp[j++].v;					// copy non-zero row value from sparse matrix into frontal matrix
			else {
				data[jFM] = bHsp[j++].v;					// fill-in coincident with sparse matrix index, copy value and advance both
				j2++;
			}
			idxCR[jFM++] = c1;
		}
		// copy eventual values remaining in sparse matrix row
		while (j <= nContribC) { data[jFM] = bHsp[j].v; idxCR[jFM++] = bHsp[j++].c; }

		int i = offV, i2 = 1, iFM = jP, iFM2 = cTot; p = bVsp[offV].r;
		while (contribR[i2] < p) i2++;						// skip past contrib.row indexes lower than current pivot

		while (i <= nContribR && i2 < nContribR2) {
			int r1 = bVsp[i].r;
			if (r1 > contribR[i2]) {
				idxCR[iFM2++] = contribR[i2++];				// fill-in from child matrices happened
			} else if (r1 < contribR[i2])
				data[iFM] = bVsp[i++].v;					// copy non-zero column value from sparse matrix into frontal matrix
			else {
				data[iFM] = bVsp[i++].v;					// fill-in coincident with sparse matrix index, copy value and advance both
				i2++;
			}
			iFM += cTot;									// advance in frontal pivot column
			idxCR[iFM2++] = r1;
		}
		// copy eventual values remaining in sparse matrix column
		while (j <= nContribC) { data[jFM] = bHsp[j].v; idxCR[jFM++] = bHsp[j++].c; }
	}




	// method is supplied with a pivot/vertex index list (vList) carrying specific tree construction ordering
	// method constructs a frontal matrix-carrying DAG
	// the structure of the list is implicitly forming a binary tree:
	// the index list repeats a vertex index to specify that next three indexes in the list
	// form a branch, but if the index appears for the first time, then it is a leaf frontal matrix
	FrontalMatrix buildFMDAG(NSPMatrix A, int[] vList) {
		
		if (A.M != A.N) throw new RuntimeException("FrontalMatrix.buildDAG(): Matrix not square.");
		// the refList will be filled up with references to created frontal matrices facilitating fast check for branches
		// there can only be as many frontal matrices as there are pivots (M = N) in a square matrix
		FrontalMatrix[] refList = new FrontalMatrix[A.M];
		
		for (int i = 0; i < vList.length; i++) {
			int fm1Idx = vList[i];
			// a null in refList means that vertex wasn't created yet and is a leaf vertex
			if (refList[fm1Idx] == null)
				refList[fm1Idx] = new FrontalMatrix(A, A.M, 0, 0, 0, 0, 0);
			// leaf node exists, the appearance of repeated index means it forms a branch with the two next indexes
			// the two child matrices must have been constructed beforehand, otherwise vList was incorrectly layouted
			else {
				int fm2Idx = vList[++i], fm3idx = vList[++i];
				if (refList[fm1Idx] == null || refList[fm2Idx] == null)
					throw new RuntimeException("FrontalMatrix.buildDAG(): DAG build ordering list incorrectly ordered");
				refList[fm3idx] = extendAdd(fm3idx, refList[fm1Idx], refList[fm2Idx]);
			}
		}
		// the last index in vList is supposed to be the topmost frontal matrix, so return it's index into the refList
		return refList[vList[vList.length - 1]];
	}
	
	



			// test current pivot and lower pivot for supernode joining criterion, if current pivot can join the lower pivot as a supernode,
			// then we can skip adding edges to this vertex/pivot, as they will be identical to edges of the lower vertex/pivot

			if (M.pivotNsp[v].offH > 0 && M.pivotNsp[v].offV > 0) {	// is this vertex/pivot both a U-ancestor & L-ancestor?
				// yes it is, so it is candidate for supernode testing against next lower pivot
				// check if this & lower pivots have similar row/column patterns
				if (dagL.fitsSupernode(M, v - 1, v, 2, 1f/4f, edgeMissH, edgeMissV)) {
					// this vertex will only have one child, and that child will be in it's supernode group
					dagL.vertex[v].edge = edge = new int[1];		// only one edge needed		
					edge[0] = v - 1 | FrontalDAGVertex.SUPERNODE;	// pointing to the lower pivot as a lower supernode member
					dagL.vertex[v].edges = 1;
					dagL.edges++;
					superCount++;
					// take care also of U-DAG, which won't need any edges added across a supernode
					dagU.vertex[v] = new FrontalDAGVertex(v, new int[1]);
					continue;
				}
				while (superCount > 0)										// finished symbolic supernode assembly, assign last supernode
					dagL.vertex[v - superCount-- - 1].superIdx = v - 1;		// index to all members of supernode
			}
			
			if (edgeMissH[0] > 1) {											// are there row edge misses to integrate from assembled supernode?
				for (int im = 1, iEnd = edgeMissH[0]; im < iEnd; im++) {
					dagL.addEdge(edgeMissH[im], v + superCount, FrontalDAGVertex.L_CHILD, true);
					dagL.vertex[edgeMissH[im]].parentsL++;
				}
				edgeMissH[0] = 1;
			}
			if (edgeMissV[0] > 1) {											// are there column edge misses to integrate from assembled supernode?
				for (int im = 1, iEnd = edgeMissV[0]; im < iEnd; im++) {
					dagU.addEdge(edgeMissV[im], v + superCount, FrontalDAGVertex.U_CHILD, true);
					dagL.vertex[edgeMissH[im]].parentsU++;
				}
				edgeMissV[0] = 1;
			}
			superCount = 0;
			



	// method makes union of edges between this DAG and DAG2, method expects vertex sets to be identical
	public void uniteEdgeSetLU(FrontalDAG dag2) {
		
		boolean order = distantFirst;
		
		for (FrontalDAGVertex vtx : vertex) {
			FrontalDAGVertex vtx2 = dag2.vertex[vtx.i];			// find equivalent vertex in DAG2
			int edgeSum = vtx.edges + vtx2.edges;

			// if edges of vertex2 can be added without reallocation
			if (edgeSum <= vtx.edge.length) {
				
				int e2 = 0, e2End = vtx2.edges + vtx2.cutedges;
				// fill up cut-flagged holes of vtx first
				if (vtx2.cutedges > 0) {
					// vtx2 has holes, make sure to bypass them
					for (int e1End = vtx.edge.length, e1 = e1End - vtx.cutedges; e1 < e1End && e2 < e2End; e2++)
						if (vtx2.edge[e2] != -1) {
							
							int e5 = vtx.edgeIndexS(vtx2.edge[e2], order);		// check if we're adding a duplicate edge
							if (e5 >= 0) {
								vtx.set_LU_edge(e5);							// found L-edge & U-edge duplicates, set to LU-edge
								if (vertex[vtx2.edge(e2)].parentLU > vtx.i)		// set child's parent-LU index if a closer parent is found
									vertex[vtx2.edge(e2)].parentLU = vtx.i;
								edgeSum--;
							} else {
								vtx.edge[vtx.edge[e1++]] = vtx2.edge[e2];		// unique edge copy
								vtx.cutedges--;
								edges++;
							}
						}
				} else {
					// vtx2 had no holes to caretake
					for (int e1End = vtx.edge.length, e1 = e1End - vtx.cutedges; e1 < e1End && e2 < e2End; e1++, e2++) {
						
						int e5 = vtx.edgeIndexS(vtx2.edge[e2], order);			// check if we're adding a duplicate edge
						if (e5 >= 0) {
							vtx.set_LU_edge(e5);								// found L-edge & U-edge duplicates, set to LU-edge
							if (vertex[vtx2.edge(e2)].parentLU > vtx.i)			// set child's parent-LU index if a closer parent is found
								vertex[vtx2.edge(e2)].parentLU = vtx.i;
							edgeSum--;
						}
						else {
							vtx.edge[vtx.edge[e1]] = vtx2.edge[e2];				// unique edge copy
							vtx.cutedges--;
							edges++;
						}
					}
				}
				
				// copy rest unto end of vertex 1's edge array, skip flagged edges in vertex 2
				if (vtx2.cutedges > 0) {
					for (int e1 = vtx.edges; e2 < e2End; e2++)
						if (vtx2.edge[e2] != -1) {
							int e5 = vtx.edgeIndexS(vtx2.edge[e2], order);		// check if we're adding a duplicate edge
							if (e5 >= 0) {
								vtx.set_LU_edge(e5);							// found L-edge & U-edge duplicates, set to LU-edge
								if (vertex[vtx2.edge(e2)].parentLU > vtx.i)		// set child's parent-LU index if a closer parent is found
									vertex[vtx2.edge(e2)].parentLU = vtx.i;
								edgeSum--;
							} else {
								vtx.edge[e1++] = vtx2.edge[e2];					// unique edge copy
								edges++;
							}
						}
				} else
					for (int e1 = vtx.edges; e2 < e2End; e2++) {
						
						int e5 = vtx.edgeIndexS(vtx2.edge[e2], order);			// check if we're adding a duplicate edge
						if (e5 >= 0) {
							vtx.set_LU_edge(e5);								// found L-edge & U-edge duplicates, set to LU-edge
							if (vertex[vtx2.edge(e2)].parentLU > vtx.i)			// set child's parent-LU index if a closer parent is found
								vertex[vtx2.edge(e2)].parentLU = vtx.i;
							edgeSum--;
						} else {
							vtx.edge[e1++] = vtx2.edge[e2];						// unique edge copy
							edges++;
						}
					}
				vtx.edges = edgeSum;
	
			// reallocation necessary, create new array
			} else {
				int e3 = 0;
				int[] edge3 = new int[trimToAllocBlock(edgeSum)];
	
				// copy over edges of vtx, skipping delete-flagged ones
				if (vtx.cutedges > 0) {
					for (int e1 = 0, l1 = vtx.edges + vtx.cutedges; e1 < l1; e1++)
						if (vtx.edge[e1] != -1) edge3[e3++] = vtx.edge[e1];
					vtx.cutedges = 0;
				// copy over edges of vtx, no delete-flagged check
				} else {
					for (int e1 = 0, l1 = vtx.edges; e1 < l1; e1++)
						edge3[e3++] = vtx.edge[e1];
				}		
				
				// copy over edges of vtx2, skipping delete-flagged ones
				if (vtx2.cutedges > 0) {
					for (int e2 = 0, l2 = vtx2.edges + vtx2.cutedges; e2 < l2; e2++) {
						int e4 = vtx2.edge[e2];
						if (e4 != -1) {
							
							int e5 = vtx.edgeIndexS(e4, order);						// check if we're adding a duplicate edge
							if (e5 >= 0) {
								edge3[e5] |= FrontalDAGVertex.LU_CHILD;				// found L-edge & U-edge duplicates, set to LU-edge
								if (vertex[vtx2.edge(e2)].parentLU > vtx.i)			// set child's parent-LU index if a closer parent is found
									vertex[vtx2.edge(e2)].parentLU = vtx.i;
							} else {
								edge3[e3++] = vtx2.edge[e2];						// unique edge copy
								edges++;
							}
						}
					}
				// copy over edges of vtx2, no delete-flagged check
				} else {
					for (int e2 = 0, l2 = vtx2.edges; e2 < l2; e2++) {
						
						int e5 = vtx.edgeIndexS(vtx2.edge[e2], order);				// check if we're adding a duplicate edge
						if (e5 >= 0) {
							edge3[e5] |= FrontalDAGVertex.LU_CHILD;					// found L-edge & U-edge duplicates, set to LU-edge
							if (vertex[vtx2.edge(e2)].parentLU > vtx.i)				// set child's parent-LU index if a closer parent is found
								vertex[vtx2.edge(e2)].parentLU = vtx.i;
						} else {
							edge3[e3++] = vtx2.edge[e2];							// unique edge copy
							edges++;
						}
					}
				}
				vtx.edge = edge3;
				vtx.edges = e3;
			}
		}
	}



//			if (distantFirst) {
//				// iterate from start of row-wise nodes of L-part of M and of column-wise nodes of U-part of M
//				int iH = 0, iV = 0;
//				for (; iH < toPivotH && iV < toPivotV; e++) {
//					if (bHsp[iH].c < bVsp[iV].r) {
//						edge[e] = bHsp[iH++].c | FrontalDAGVertex.L_CHILD;		// L-child found in L-part
//					} else if (bHsp[iH].c > bVsp[iV].r) {
//						edge[e] = bVsp[iV++].r | FrontalDAGVertex.U_CHILD;		// U-child found in U-part
//					} else {
//						edge[e] = bVsp[iV++].r | FrontalDAGVertex.LU_CHILD;		// L-child and U-child found in L & U
//						if (dagLU.vertex[edge[e]].parentLU > v)					// if this vertex is a closer LU-ancestor to found LU-child than previous
//							dagLU.vertex[edge[e]].parentLU = v;					// ...reassign LU-child's LU-ancestor to this vertex
//						iH++;
//					}
//				}
//				// if elements are left in bHsp or bVsp, finish them off
//				for (; iH < toPivotH; iH++, e++) edge[e] = bHsp[iH].c | FrontalDAGVertex.L_CHILD;
//				for (; iV < toPivotV; iV++, e++) edge[e] = bVsp[iV].r | FrontalDAGVertex.U_CHILD;
//				
//			} else {
//				int iH = toPivotH - 1, iV = toPivotV - 1;
//				for (; iH >= 0 && iV >= 0; e++) {
//					if (bHsp[iH].c < bVsp[iV].r) {
//						edge[e] = bHsp[iH--].c | FrontalDAGVertex.L_CHILD;		// L-child found in L-part
//					} else if (bHsp[iH].c > bVsp[iV].r) {
//						edge[e] = bVsp[iV--].r | FrontalDAGVertex.U_CHILD;		// U-child found in U-part
//					} else {
//						edge[e] = bVsp[iV--].r | FrontalDAGVertex.LU_CHILD;		// L-child and U-child found in L & U
//						iH--;
//					}
//				}
//				// if elements are left in bHsp or bVsp, finish them off
//				for (; iH >= 0; iH--, e++) edge[e] = bHsp[iH].c | FrontalDAGVertex.L_CHILD;
//				for (; iV >= 0; iV--, e++) edge[e] = bVsp[iV].r | FrontalDAGVertex.U_CHILD;
//			}
//




	// method adds child-looking edges to DAG, and is best called when the DAG construction has been finished,
	// to keep down complexity and avoid mixing up operations meant for the parent-looking edges
	public void createChildEdges() {
		for (FrontalDAGVertex vtx : vertex) {									// for all vertices in DAG
			if (vtx.cutedges > 0) {
				for (int e = 0, eEnd = vtx.edges + vtx.cutedges; e < eEnd; e++)		// for all edge destinations from this vertex
					if (vtx.edge[e] != -1) 											// if it's not a deleted edge
						addEdge(vtx.edge(e), vtx.i, 0, false);						// add edge pointing from parent toward this vertex
			} else {
				for (int e = 0, eEnd = vtx.edges; e < eEnd; e++)					// for all edge destinations from this vertex
					addEdge(vtx.edge(e), vtx.i, 0, false);							// add edge pointing from parent toward this vertex
			}
		}
	}


	// transitively reduces graph
	public void transitiveReduction() {
		for (int jV = 0; jV < verts; jV++) {
			for (int iV = 0; iV < verts; iV++) {
				if (iV != jV && edgeTo(iV, jV)) {
					for (int kV = 0; kV < verts; kV++) {
						if (jV != kV && edgeTo(jV, kV))
							cutEdge(iV, kV);
					}
				}
			}
		}
	}

	// transitively reduces a graph describing an upper or lower triangle of a connectivity matrix
	// it is assumed that opposing triangle is already zero and doesn't need reduction
	public void transitiveReductionLU() {
		for (int jV = 0; jV < verts; jV++) {
			for (int iV = jV + 1; iV < verts; iV++) {
				if (iV != jV && edgeTo(iV, jV)) {
					for (int kV = iV + 1; kV < verts; kV++) {
						if (jV != kV && edgeTo(jV, kV))
							cutEdge(iV, kV);
					}
				}
			}
		}
	}




            // alternative depermutation code for NSPMatrix.backsubstituteLU()

       		for (int i = 0, offVi = 0; i < N; i++) {

			boolean bImatch = offVi < nNodes && bVspB[offVi].r == i ? true : false;
			// the permutations of decomposition stage need to be unpermuted during the passes
			int ip = mutatorLU[i];
			int offVip = findHVspNode(bVspB, 0, nNodes - 1, ip, -1);				// see if b[ip] exists in sparse array
			if (offVip >= 0) {														// if b[ip] is a non-zero, existing node...
				sum = bVspB[offVip].v;												// sum = b[ip]
				if (bImatch)														// if b[i] matches current row index i (thus is non-zero)
					bVspB[offVip].v = bVspB[offVi].v;								// b[ip] = b[i] (assigning to existing node)
				else {
					removeLocalHVspNode(aVspB, offVip, 1);							// if assigning to a zero, remove the node
					nNodes = aVspB.nodes;
					vectorB.nNZ--;
					bVspB = aVspB.array;
				}
			} else {
				sum = 0;
				if (bImatch) {														// create node b[ip] only if b[i] is nonzero
					NspNode newNode = bVspB[offVi].clone();
					newNode.r = ip;
					insertLocalHVspNode(aVspB, -offVip-1, 1, newNode);				// b[ip] = b[i]	(assigning by inserting a node)
					insertLocalHVspNode(vectorB.Hsp[ip], 0, 0, newNode);
					nNodes = aVspB.nodes;
					vectorB.nNZ++;
					bVspB = aVspB.array;
				}
			}

			if (ii >= 0)
				sum -= multiplyStartEndHVsp(bLU[1].Hsp[i], aVspB, 0, 1, ii, i - 1);	// for (ii <= j < i), sum -= a[i][j] * b[j]
			else
				if (!nearZero(sum)) ii = i;					// nonzero element found, we'll have to do the sums in loop above from now on

			if (bImatch) {
				if (nearZero(sum))	{
					removeLocalHVspNode(aVspB, offVi, 1);							// b[i] = sum (b[i] exists as nonzero, but is assigned a zero)
					bVspB = aVspB.array;
					vectorB.nNZ--;
				} else bVspB[offVi].v = sum;										// b[i] = sum (simple assignment if b[i] exists as non-zero)
				offVi++;
			} else {
				if (!nearZero(sum)) {
					NspNode newNode = new NspNode(i, 0, sum, 0, offVi, 0);
					insertLocalHVspNode(aVspB, offVi, 1, newNode);					// b[i] = sum (b[i] was zero/nonexistent, assigned value was nonzero)
					insertLocalHVspNode(vectorB.Hsp[i], 0, 0, newNode);				// insert also to horisontal aspect
					bVspB = aVspB.array;
					vectorB.nNZ++;
				}																	// b[i] = sum (b[i] was zero and assignment was zero, nothing happens)
			}
		}

 		NspNode[] pivotNspA = bLU[1].pivotNsp;
		for (int i = N - 1, offVi = nNodes - 1; i >= 0; i--) {						// backsubstitution pass

			while (offVi > 0 && bVspB[offVi].r > i) offVi--;						// seek backwards in sparse array for a row matching or below i
			boolean bImatch = (bVspB[offVi].r == i ? true : false);
			if (bImatch)	sum = bVspB[offVi].v;									// sum = b[i] (zero if b[0] is nonexistante/zero value
			else 			sum = 0;
			sum -= multiplyStartEndHVsp(lHspLU[i], aVspB, 0, 1, ii, i - 1);			// for (i+1 <= j < N), sum -= a[i][j] * b[j]

			// store an element of solution vector X
			if (bImatch)
				if (nearZero(sum)) {
					removeLocalHVspNode(aVspB, offVi, 1);							// if assigning node to a zero, remove that node
					nNodes = aVspB.nodes;
					bLU[0].nNZ--;
					bVspB = aVspB.array;
				} else
					bVspB[offVi].v = sum / pivotNspA[i].v;							// b[i] = sum / a[i][i] (case when b[i] exists as nonzero value)
			else {
				if (!nearZero(sum)) {
					NspNode newNode = new NspNode(i, 0, sum / pivotNspA[i].v, 0, offVi, 0);
					insertLocalHVspNode(aVspB, offVi, 1, newNode);					// b[i] = sum / a[i][i] (b[i] is zero/nonexistent, insert new node
					insertLocalHVspNode(vectorB.Hsp[i], 0, 0, newNode);				// insert also to horisontal aspect
					bLU[0].nNZ++;
				}
			}
		}










	// factorises/decomposes matrix into two diagonal matrices U and V, useful for the LU backsubstitution linear solving method:
	//		uuu			v..
	// U:	.uu		L:	vv.
	//		..u			vvv
	// TODO: debugging needed, do not use
	public Matrix[] decomposeLU() {
		
		if (M != N)	throw new RuntimeException("Matrix.decomposeLU(): Matrix not square.");
		if (M < 1)	throw new RuntimeException("Matrix.decomposeLU(): Invalid matrix.");

		// all diagonal elements must be nonzero
		for (int d = 0; d < M; d++)
			if (nearZero(data[d * M + d])) { status |= SINGULAR_MATRIX; return null; }
			
		Matrix[] lLU = new Matrix[2];
		lLU[0] = new Matrix("L", M, N, Matrix.Type.Null);
		lLU[1] = new Matrix("U", M, N, Matrix.Type.Null);
		double[] dataL = lLU[0].data, dataU = lLU[1].data;

		for (int c1 = 0; c1 < N; c1++) {
			
			// calculate u(r,c)
			if (c1 == 0)	dataU[0] = data[0];
			else
				for (int r = 0; r <= c1; r++) {
					int rN = r * N;
					double luSum = 0;
					for (int k = 0; k < r; k++)
						luSum += dataL[rN + k] * dataU[k * N + c1];
					dataU[rN + c1] = data[rN + c1] - luSum;
				}
			
			// calculate l(r,c)
			double uDiag = 1.0 / dataU[c1 * N + c1];
			for (int r = c1; r < N; r++) {
				int rN = r * N;
				double luSum = 0;
				if (c1 == 0) dataL[rN] = data[rN];
				else {
					for (int k = 0; k < c1; k++)
						luSum += dataL[rN + k] * dataU[k * N + c1];
					dataL[rN + c1] = (data[rN + c1] - luSum) * uDiag;
				}
			}
		}
		
		if (DEBUG_LEVEL > 1) {
			System.out.println("decomposeLU() result:");
			System.out.println(lLU[0].toString());
			System.out.println(lLU[1].toString());
		}
		return lLU;
	}
	
	
	
		
	// method takes the factorised L & U triangular matrices applying them on this constant vector to solve
	// a linear system where only the constant vector is changing, the matrix coefficients assumed to be fixed
	// method returns the solution vector x
	public Matrix backSubstituteLU(Matrix L, Matrix U) {
		
		Matrix cp = new Matrix("c'", U.M, 1, Matrix.Type.Null);					// c' needs to be generated from input constant vector c
		String newname;
		if (Matrix.DEBUG_LEVEL > 1) newname = "x((LU)^-1*" + this.name + ")";
		else						newname = "x";
		Matrix x = new Matrix(newname, U.M, 1, Matrix.Type.Null);									// the solution vector x
		double[] dataU = U.data, dataV = L.data, datacp = cp.data, datax = x.data;

		// loop handles every element of c, c', V, U and x
		// c'(r) = (c(r) - sum(v(r,k) * c'(k))) / v(r,r)
		datacp[0] = data[0] / dataV[0];
		for (int r = 1; r < M; r++) {
			int rN = L.N * r;
			double sum = 0;
			for (int k = 0; k < r; k++) sum += dataV[rN + k] * datacp[k];
			datacp[r] = (data[r] - sum) / dataV[rN + r];
		}

		// x(r) = (c'(r) - sum(u(r,k) * x(k))) / u(r,r)
		int r = M - 1;
		datax[r] = datacp[r] / dataU[r * U.N + r--];
		for (; r >= 0; r--) {
			int rN = U.N * r;
			double sum = 0;
			for (int k = r + 1; k < M; k++) sum += dataU[rN + k] * datax[k];
			datax[r] = (datacp[r] - sum) / dataU[rN + r];
		}

		if (DEBUG_LEVEL > 1) {
			System.out.println("backSubstituteLU solver:");
			System.out.println(x.toString());
		}
		return x;	
	}
	



	private static DoubleBuffer bufSWA, bufSWB, bufSWC;	// preallocated DirectBuffer for operations upto specific matrix size
	
	// method preallocates a DirectBuffer for a matrix operation of a certain size with a certain recursion cutoff
	public static boolean allocateStrasWin(int Mreqsize, int truncP) {

		if (Mreqsize < 2) throw new RuntimeException("Matrix.allocateStrasWin(): Invalid matrix dimensions.");
		if (truncP < 2) throw new RuntimeException("Matrix.allocateStrasWin(): Invalid truncation point.");
		if (truncP > Mreqsize) truncP = Mreqsize;
		
		int Msize = 2, memSize = 0;
		// do 2^(n+1) until we reach truncation point (to make sure we'll encompass the smallest submatrix size)
		for (; Msize < truncP; Msize <<= 1);		
		for (; Msize < Mreqsize; Msize <<= 1)		// do 2^(n+1) until we reach or excel the provided matrix size
			memSize += truncP * truncP * 8;			// we need 8 allocations per recursion level/submatrix
		memSize += Msize * Msize * 2;				// Matrix A & B will also be copied to direct buffer
		
		bufSWA = ByteBuffer.allocateDirect(memSize * 8).asDoubleBuffer();
		if (DEBUG_LEVEL > 2)
	        System.out.println("bufSW is direct: " + bufSWA.isDirect() + "and has " + (bufSWA.hasArray() ? "a" : "no") + "backing array.");
		return true;
	}




	public static Matrix multiplyStrasWin(Matrix A, Matrix B, int truncP, boolean useDBversion) {
		
		if (A.M < 1 || A.N < 1 || B.M < 1 || B.N < 1) throw new RuntimeException("Matrix.multiply(): Invalid matrix dimensions.");
		if (A.N != B.M) throw new RuntimeException("Matrix.multiply(): Nonmatching matrix dimensions.");
		mulSW_DEBUG = mulFlopsSW_DEBUG = mulAdopsSW_DEBUG = 0;
				
		// squarify and expand matrices to nearest 2^n size
		int majorM = A.M > A.N ? A.M : A.N, newM;
		for (newM = 2; newM < majorM; newM <<= 1);		// do 2^(n+1) until we reach or excel major size of the matrices
		if (A.M != A.N || newM != majorM) {
			A = A.rescale(0, 0, newM, newM, false);		// no BitImage needed for transient data
			B = B.rescale(0, 0, newM, newM, false);
		}
		if (truncP > newM) truncP = newM;				// truncation point can't be larger than the matrix

		String newname;
		if (Matrix.DEBUG_LEVEL > 1) newname = "(" + A.name + "." + B.name + ")";
		else						newname = "W" + Matrix.nameCount++;
		Matrix C = new Matrix(newname, newM, newM, Matrix.Type.Null);
		
		if (useDBversion) {
			int Msize = newM * newM;
			bufSWA.get(A.data, 0, Msize);
			bufSWA.reset();
			bufSWB = bufSWA.duplicate();
			bufSWC = bufSWA.duplicate();
			bufSWB.position(Msize).mark();
			bufSWB.get(B.data, Msize, Msize);
			bufSWB.reset();
			bufSWC.position(Msize << 1).mark();
			// at start, offsA,offsB,offsC point to A, B, C matrix data offsets, the submatrices offset points beyond those three
			int[] subInfo = {truncP, newM, 0, Msize, Msize << 1, newM, newM, newM, Msize * 3};
			//multiplyStrasWin2DB(bufSWA, bufSWB, bufSWC, subInfo);
			bufSWC.reset();
			bufSWC.put(C.data, Msize << 1, Msize);
		} else {

			buffer2x2StrasWin = new double[8][truncP > 16 ? 16*16 : truncP*truncP];
			
			// subInfo carries along following data:
			// (truncP) the matrix size truncation point when standard multiplicator is used instead
			// (dim) the current submatrix dimension 
			// 3x offsets into the flat datafields, 3x the matrix width of the datafields
			int[] subInfo = {truncP, newM, 0, 0, 0, newM, newM, newM};
			multiplyStrasWin2(A.data, B.data, C.data, subInfo);
		}
		if (DEBUG_LEVEL > 1) System.out.println(C.toString());
		return C;

	}



	// the preallocated DirectBuffer version of Strassen-Winograd multiplier, using bufSWA, bufSWB, bufSWC pointers
//	public static void multiplyStrasWin2DB(DoubleBuffer dA, DoubleBuffer dB, DoubleBuffer dC, int[] subInfo) {
//
//		int truncP = subInfo[0], dim = subInfo[1], offset = subInfo[8];
//		int offsA = subInfo[2], offsB = subInfo[3], offsC = subInfo[4];
//		int dimA = subInfo[5], dimB = subInfo[6], dimC = subInfo[7];
//		Matrix.mulSW_DEBUG++;
//		Matrix.mulFlopsSW_DEBUG += 4;
//
//		// if we reached base case of 2x2, return straight 2x2 multiplication
//		if (dim == 2) {
//			dA.position(offsA);
//			dB.position(offsB);
//			dC.position(offsC);
//			double a11 = dA.get(), a12 = dA.get(), a21 = dA.get(offsA + dimA), a22 = dA.get(offsA + dimA + 1);
//			double b11 = dB.get(), b12 = dB.get(), b21 = dB.get(offsB + dimB), b22 = dB.get(offsB + dimB + 1);
//			dC.put(a11 * b11 + a12 * b21);
//			dC.put(a11 * b12 + a12 * b22);
//			dC.position(offsC + dimC);
//			dC.put(a21 * b11 + a22 * b21);
//			dC.put(a21 * b12 + a22 * b22);
//			Matrix.mulFlopsSW_DEBUG += 8;
//			Matrix.mulAdopsSW_DEBUG += 11;
//			return;
//		}
//		
//		// if we reached the recursion truncation point, multiply current submatrix with standard algorithm
//		if (truncP >= dim) {
//			Matrix.mulFlopsSW_DEBUG += dim * 2 + dim * dim + dim * dim * dim;
//			Matrix.mulAdopsSW_DEBUG += dim * 2 + dim * dim + dim * dim * dim * 2;
//			
//			for (int i = 0; i < dim; i++) {
//				int ioffsA = offsA + i * dimA, ioffsC = offsC + i * dimC;
//				for (int j = 0; j < dim; j++) {
//					dA.position(ioffsA + j);
//					dB.position(offsB + j * dimB);
//					dC.position(ioffsC);
//					double v = dA.get();
//					if (v < -Matrix.ROUNDOFF_ERROR || v > Matrix.ROUNDOFF_ERROR) {
//						for (int k = 0; k < dim; k++)
//							dC.put(ioffsC + k, dC.get() + v * dB.get());
//					}
//				}
//			}		
//			return;
//		}
//		
//		int sdim2 = dim>>1, size = dim * dim, ssize = size>>2;		// next sublevel dimensions
//		// offsets to middle row (half-way into submatrix) of current recursive level
//		int hoffsA = dimA * sdim2, hoffsB = dimB * sdim2, hoffsC = dimC * sdim2;
//		// the skips tell how many steps to skip to get to next row in the data during incremental operations
//		int skipA = dimA - sdim2, skipB = dimB - sdim2, skipC = dimC - sdim2;
//
//		// A21 + A22 -> S1
//		DoubleBuffer dS1 = dA.duplicate();
//		dS1.position(offset);
//		for (int i = 0, offsA21 = offsA + hoffsA, offsA22 = offsA21 + sdim2; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++)	 dS1.put(dA.get(offsA21++) + dA.get(offsA22++));
//			offsA21 += skipA; offsA22 += skipA;
//		}
//
//		// B12 - B11 -> T1
//		DoubleBuffer dT1 = dA.duplicate();
//		int offsetT1 = offset + ssize;
//		dT1.position(offsetT1);
//		for (int i = 0, offsB11 = offsB, offsB12 = offsB + sdim2; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++)	 dT1.put(dB.get(offsB12++) - dB.get(offsB11++));
//			offsB12 += skipB; offsB11 += skipB;
//		}
//
//		// S1 . T1 -> P5
//		DoubleBuffer dP5 = dA.duplicate();
//		int offsetP5 = offsetT1 + ssize;
//		int[] subInfo3 = {truncP, sdim2, offset, offsetT1, offsetP5, sdim2, sdim2, sdim2, offset + ssize * 8};
//		multiplyStrasWin2DB(dS1, dT1, dP5, subInfo3);
//
//		// B22 - T1 -> T2 (=T1)
//		DoubleBuffer dT2 = dT1;
//		dT2.position(offsetT1);
//		for (int i = 0, offsB22 = offsB + hoffsB + sdim2, offs = offsetT1; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	 dT2.put(dB.get(offsB22++) - dT1.get(offs++));
//			offsB22 += skipB;
//		}
//
//		// S1 - A11 -> S2 (=S1)
//		DoubleBuffer dS2 = dS1;
//		dS2.position(offset);
//		for (int i = 0, offsA11 = offsA, offs = offset; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	dS2.put(dS1.get(offs++) - dA.get(offsA11++));
//			offsA11 += skipA;
//		}
//			
//		// S2 . T2 -> P6
//		DoubleBuffer dP6 = dA.duplicate();
//		int offsetP6 = offsetP5 + ssize;
//		subInfo[4] = offsetP6;
//		multiplyStrasWin2DB(dS2, dT2, dP6, subInfo3);
//
//		// A12 - S2 -> S4
//		DoubleBuffer dS4 = dA.duplicate();
//		int offsetS4 = offsetP6 + ssize;
//		dS2.position(offset);
//		dS4.position(offsetS4);
//		for (int i = 0, offsA12 = offsA + sdim2, offs = 0; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	 dS4.put(dA.get(offsA12++) - dS2.get());
//			offsA12 += skipA;
//		}
//
//		// S4 . B22 -> P3
//		DoubleBuffer dP3 = dA.duplicate();
//		int[] subInfo5 = {truncP, sdim2, 0, offsB + hoffsB + sdim2, 0, sdim2, dimB, sdim2};
//		multiplyStrasWin2DB(dS4, dB, dP3, subInfo5);
//
//		// A11 - A21 -> S3 (=S1=S2)
//		double[] dS3 = dS2;
//		for (int i = 0, offsA11 = offsA, offsA21 = offsA + hoffsA, offs = 0; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	 dS3[offs] = dA[offsA11++] - dA[offsA21++];
//			offsA11 += skipA; offsA21 += skipA;
//		}
//		
//		// B22 - B12 -> T3 (=S4)
//		double[] dT3 = dS4;
//		for (int i = 0, offsB12 = offsB + sdim2, offsB22 = offsB12 + hoffsB, offs = 0; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	 dT3[offs] = dB[offsB22++] - dB[offsB12++];
//			offsB22 += skipB; offsB12 += skipB;
//		}
//
//		// T2 - B21 -> T4 (=T1=T2)
//		double[] dT4 = dT2;
//		for (int i = 0, offsB21 = offsB + hoffsB, offs = 0; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	 dT4[offs] = dT2[offs] - dB[offsB21++];
//			offsB21 += skipB;
//		}
//
//		// A11 . B11 -> P1
//		int[] subInfo2 = {truncP, sdim2, offsA, offsB, 0, dimA, dimB, sdim2};
//		double[] dP1 = (sdim2 == 2 ? buffer2x2StrasWin[6] : new double[ssize]);
//		multiplyStrasWin2(dA, dB, dP1, subInfo2);
//
//		// S3 . T3 -> P7
//		double[] dP7 = (sdim2 == 2 ? buffer2x2StrasWin[7] : new double[ssize]);
//		multiplyStrasWin2(dS3, dT3, dP7, subInfo3);
//
//		// P1 + P6 -> U2 (=T3=S4)
//		double[] dU2 = dT3;
//		for (int i = 0, offs = 0; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	dU2[offs] = dP1[offs] + dP6[offs];
//		}
//
//		// A12 . B21 -> P2 (=P6)
//		subInfo2[2] += sdim2;
//		subInfo2[3] += hoffsB;
//		double[] dP2 = dP6;
//		multiplyStrasWin2(dA, dB, dP2, subInfo2);
//
//		// P1 + P2 -> C11
//		for (int i = 0, offsC11 = offsC, offs = 0; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	dC[offsC11++] = dP1[offs] + dP2[offs];
//			offsC11 += skipC;
//		}
//
//		// A22 . T4 -> P4 (=P2)
//		double[] dP4 = dP2;
//		subInfo2[2] = offsA + hoffsA + sdim2;
//		subInfo2[3] = 0;
//		subInfo2[5] = dimA;
//		subInfo2[6] = sdim2;
//		multiplyStrasWin2(dA, dT4, dP4, subInfo2);
//							
//		// U2 + P7 -> U3 (=T1=T2=T4)
//		double[] dU3 = dT4;
//		for (int i = 0, offs = 0; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	dU3[offs] = dU2[offs] + dP7[offs];
//		}
//
//		// U2 + P5 -> U4 (=S1=S2=S3)
//		double[] dU4 = dS3;
//		for (int i = 0, offs = 0; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	dU4[offs] = dU2[offs] + dP5[offs];
//		}
//
//		// U4 + P3 -> U5 (=T3=S4=U2), C12
//		double[] dU5 = dU2;
//		for (int i = 0, offsC12 = offsC + sdim2, offs = 0; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	 dU5[offs] = dC[offsC12++] = dU4[offs] + dP3[offs];
//			offsC12 += skipC; 
//		}
//
//		// U3 - P4 -> C21
//		for (int i = 0, offsC21 = offsC + hoffsC, offs = 0; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	dC[offsC21++] = dU3[offs] - dP4[offs];
//			offsC21 += skipC;
//		}
//
//		// U3 + P5 -> C22
//		for (int i = 0, offsC22 = offsC + hoffsC + sdim2, offs = 0; i < sdim2; i++)  {
//			for (int j = 0; j < sdim2; j++, offs++)	dC[offsC22++] = dU3[offs] + dP5[offs];
//			offsC22 += skipC; 
//		}
//		
//		Matrix.mulAdopsSW_DEBUG += (23 + sdim2 * 31);
//	}





	// conditioning for precision and iterative methods: swap in the largest elements of rows into diagonal positions
	// the constant vector c needs to be swapped as well, if set to null it is ignored
	// method constructs array "mutator" with the mutated indexes for facilitating reconstitution of the solved vector
	public void conditionDiagonal(Matrix c, boolean swapMethod, boolean doBitImage) {
		
		if (M != N)									throw new RuntimeException("Matrix.conditionDiagonal(): Matrix not square.");
		if (M < 1)									throw new RuntimeException("Matrix.conditionDiagonal(): Invalid matrix.");
		if (c != null && (M != c.M || c.N != 1))	throw new RuntimeException("Matrix.conditionDiagonal(): Invalid constant vector.");
				
		double[] data = this.data, newdata = new double[M*N];
		if (swapMethod) {
			mutator = new int[M + 1];
			for (int i = 0; i < M; i++) mutator[i] = i;
		}
		
		for (int r1 = 0, m; r1 < M; r1++) {
			int r1N = r1 * N;
			double a_r1r1 = data[r1N + r1];
			if (a_r1r1 < 0) a_r1r1 = -a_r1r1;
			// find largest (absolute) element in current row (skip checking previous rows for swapMethod)
			if (swapMethod) {
				// apply method that swaps row r1 & row r2 if diagonals of both rows get larger on swapping 
				for (int r2 = 0; r2 < N; r2++) {
					if (r1 != r2) {
					int r2N = r2 * N;

					double a_r2r1 = data[r2N + r1], a_r1r2 = data[r1N + r2], a_r2r2 = data[r2N + r2];
					if ((a_r1r1 < a_r2r1 || a_r1r1 > -a_r2r1) && (a_r1r2 >= a_r2r2 || a_r1r2 <= -a_r2r2)) {
						swap(r1, r2);
						if (c != null) c.swap(r1, r2);	// swap matching elements in vector c
						m = mutator[r1];				// swap indexes in mutator array
						mutator[r1] = mutator[r2];
						mutator[r2] = m;
					}
					}
				}
			} else {
				// apply adding method which adds row r2 to r1 if it provides a larger value for diagonal element of row r1
				int rMaxDiag = 0;
				double vMaxDiag = 0;
				// find the largest diagonal from all other rows than r1
				for (int r2 = 0; r2 < N; r2++) {
					if (r2 != r1) {
						double a_r2r1 = data[r2 * N + r1];
						if (a_r2r1 < 0) a_r2r1 = -a_r2r1;
						if (vMaxDiag < a_r2r1) {
							rMaxDiag = r2;
							vMaxDiag = a_r2r1;
						}
					}
				}
				// move over into newdata the row with max-value in diagonal element position added with row of the current diagonal element
				//if (vMaxDiag > a_r1r1) {
					int rMax = rMaxDiag * N;
					for (int c1 = 0; c1 < N; c1++) {
						newdata[r1N + c1] += data[r1N + c1] + data[rMax + c1];
						if (c != null) c.data[r1] += c.data[rMaxDiag];
					}
				//}
			}
		}
		if (!swapMethod) this.data = newdata;
		if (DEBUG_LEVEL > 1) System.out.println("conditionDiagonal():\n" + toString());
		if (doBitImage) bitImage.make();
	}
